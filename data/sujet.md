# DIA WiSe2023

## 1.2 Entity Resolution Pipeline (45/100 points)

Construct an ER pipeline to match the entries from DBLP_1995_2004. csv and ACM_1995_2004. csv that refer to the same publication. The pipeline should include the following steps:

- **Blocking**: Use a blocking scheme to assign the entries to one or more buckets based on blocking keys.
  - Example blocking methods are
    - structured keys, n-gram blocking,
    - as well as hash- or sort-based blocking (e.g., by year ranges).
- **Matching**: For all pairs of entities in a bucket, apply a similarity function to determine if they refer to the same entity (if above a certain similarity score threshold).
  - Write all the matched pairs in a file, Matched Entities. csv.
  - To verify the ER match quality, you need a baseline.
    - Apply the same similarity function on all pairs of the datasets and use the result as your baseline.
    - Calculate the precision, recall, and F-measure of the matches generated by your ER pipeline compared to the baseline.
  - Experiment with different blocking schemes, similarity functions, and similarity score thresholds to improve match quality and reduce execution time.
- **Clustering**: Once you are happy with the matches, group together all the identified matches in clusters such that all entities within a cluster refer to the same entity. Finally, resolve the unmatched entities with a single version in the datasets and write them back to disk.

**Expected results**:

- Code for the ER pipeline, as well as
- descriptions of the techniques and
- baselines used.

The report must include

- the match quality measures and
- the execution time improvement of the ER pipeline compared to the baseline.

## 1.3 Data-Parallel Entity Resolution Pipeline (35/100 points)

Reimplement your entity resolution pipeline on top of a data-parallel computation framework such as Apache Spark, Apache Flink, or Dask. This data-parallel pipeline should produce the same results as your local pipeline (validated by comparing Matched Entities. csv of both pipelines).

Furthermore, in order to validate the scalability of your pipeline, please replicate each dataset 1 to 10 times with minor modifications of each entity's attributes, and plot the resulting execution time (x-asis: replication factor, y-axis: runtime in seconds).

Expected Results: Code for the data-parallel ER pipeline, a description of the data-parallel pipeline, and the plot of the runtime experiment.
